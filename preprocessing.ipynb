{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b8d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import Xception\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "INPUT_SIZE = (299, 299)\n",
    "FEATURE_DIM = 2048\n",
    "NUM_FRAMES = 30\n",
    "TRAIN_REAL = 'extracted_frames/train/real'\n",
    "TRAIN_FAKE = 'extracted_frames/train/fake'\n",
    "\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(INPUT_SIZE[0], INPUT_SIZE[1], 3))\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "for layer in feature_extractor.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_folder(folder_path):\n",
    "    features = []\n",
    "    frame_files = sorted([f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "\n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(folder_path, frame_file)\n",
    "        try:\n",
    "            image = Image.open(frame_path).convert(\"RGB\")\n",
    "            image = image.resize(INPUT_SIZE)\n",
    "            image_array = np.array(image).astype('float32')\n",
    "            image_array = np.expand_dims(image_array, axis=0)\n",
    "\n",
    "            processed_image = tf.keras.applications.xception.preprocess_input(image_array)\n",
    "\n",
    "            feature = feature_extractor.predict(processed_image, verbose=0).squeeze()\n",
    "            \n",
    "            features.append(feature)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a868a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_features(root_dir, label, num_frames=NUM_FRAMES, feature_dim=FEATURE_DIM):\n",
    "    X, y = [], []\n",
    "    for video_folder in tqdm(os.listdir(root_dir)):\n",
    "        video_path = os.path.join(root_dir, video_folder)\n",
    "        if not os.path.isdir(video_path):\n",
    "            continue\n",
    "\n",
    "        features = extract_features_from_folder(video_path)\n",
    "\n",
    "        if features.shape[0] == num_frames:\n",
    "            reshaped_features = features.reshape(num_frames, 1, 1, feature_dim)\n",
    "            X.append(reshaped_features)\n",
    "            y.append(label)\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15120525",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_train, y_real_train = load_dataset_features(TRAIN_REAL, 0)\n",
    "X_fake_train, y_fake_train = load_dataset_features(TRAIN_FAKE, 1)\n",
    "\n",
    "X_train_combined = np.array(X_real_train + X_fake_train)\n",
    "y_train_combined = np.array(y_real_train + y_fake_train)\n",
    "\n",
    "X_real_val, y_real_val = [], []\n",
    "X_fake_val, y_fake_val = [], []\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_combined, y_train_combined, test_size=0.2, stratify=y_train_combined, random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e72d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"dataset.h5\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "with h5py.File(save_path, \"w\") as f:\n",
    "    f.create_dataset(\"X_train\", data=X_train)\n",
    "    f.create_dataset(\"X_val\", data=X_val)\n",
    "    f.create_dataset(\"y_train\", data=y_train)\n",
    "    f.create_dataset(\"y_val\", data=y_val)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
